cost_tracking:
  budget_limits:
    daily: 100.0
    monthly: 2000.0
    per_task: 5.0
  model_costs:
    qwen/qwen-2.5-coder-32b-instruct:
    - 0
    - 0
    qwen/qwen-2.5-72b-instruct:
    - 0
    - 0
    anthropic/claude-4-opus:
    - 12
    - 60
    anthropic/claude-opus-4.1:
    - 15
    - 75
    anthropic/claude-sonnet-4.5:
    - 3
    - 15
    deepseek/deepseek-chat:
    - 0
    - 0
    google/gemini-2.5-flash-exp:
    - 2
    - 8
    google/gemini-2.5-pro-exp:
    - 10
    - 30
    meta-llama/llama-3.3-70b-instruct:
    - 0
    - 0
    mistralai/codestral-25.01:
    - 0
    - 0
    openai/gpt-5:
    - 30
    - 60
    openai/gpt-5-pro:
    - 40
    - 80
    openai/o3-pro:
    - 25
    - 50
    openai/o4-mini-high:
    - 35
    - 70
dynamic_rules:
  auto_switch:
    enabled: true
    rules:
    - condition: task_complexity > 0.9
      switch_to: QUALITY_FIRST
    - condition: remaining_budget < 100
      switch_to: COST_FIRST
    - condition: user_waiting_time > 30
      switch_to: SPEED_FIRST
    - condition: sensitive_data == true
      switch_to: PRIVACY_FIRST
  learning:
    adjust_weights_after: 100
    enabled: true
    max_weight_change: 0.1
    track_metrics:
    - task_success_rate
    - user_satisfaction
    - cost_per_task
    - time_to_completion
model_benchmarks:
  qwen/qwen-2.5-coder-32b-instruct: 73.7
  qwen/qwen-2.5-72b-instruct: 75.1
  anthropic/claude-*: 200000
  anthropic/claude-opus-4.1: 74.5
  anthropic/claude-sonnet-4.5: 77.2
  deepseek/deepseek-chat: 82.6
  google/gemini-2.0-pro-exp: 1000000
  google/gemini-2.5-pro-exp: 2000000
  meta-llama/llama-3.3-70b-instruct: 128000
  mistralai/codestral-25.01: 95.3
  openai/gpt-5: 272000
strategies:
  BALANCED:
    cost_weight: 0.5
    description: Smart mix of open and closed models. Best value for most use cases.
    model_preferences:
      architect:
        fallback:
        - openai/gpt-5-pro
        - google/gemini-2.5-pro-exp
        never_use: []
        primary:
        - qwen/qwen-2.5-72b-instruct
        - meta-llama/llama-3.3-70b-instruct
      coder:
        fallback:
        - anthropic/claude-3-7-sonnet
        - openai/gpt-5
        never_use: []
        primary:
        - qwen/qwen-2.5-coder-32b-instruct
        - deepseek/deepseek-chat
      documenter:
        fallback:
        - anthropic/claude-3-7-sonnet
        - google/gemini-2.5-flash-exp
        never_use: []
        primary:
        - meta-llama/llama-3.3-70b-instruct
        - mistralai/mistral-small-3
      researcher:
        fallback:
        - google/gemini-2.5-pro-exp
        - perplexity/r1
        never_use: []
        primary:
        - meta-llama/llama-3.3-70b-instruct
        - deepseek/deepseek-chat
      reviewer:
        fallback:
        - anthropic/claude-sonnet-4.5
        - openai/o3
        never_use: []
        primary:
        - deepseek/deepseek-chat
        - meta-llama/llama-3.3-70b-instruct
    name: Balanced Performance
    quality_weight: 0.4
    speed_weight: 0.1
    thresholds:
      escalation_threshold: 0.75
      max_acceptable_latency: 45
      min_quality_score: 0.8
  COST_FIRST:
    cost_weight: 0.9
    description: Prioritize free open-source models. Perfect for high-volume or budget-conscious
      projects.
    model_preferences:
      architect:
        fallback:
        - deepseek-ai/deepseek-v3
        - mistralai/mistral-small-3
        never_use:
        - openai/gpt-5-pro
        - anthropic/claude-opus-4.1
        primary:
        - meta-llama/llama-3.3-70b-instruct
        - alibaba/qwq-32b-preview
      coder:
        fallback:
        - mistralai/codestral-25.01
        - meta-llama/llama-3.3-70b-instruct
        never_use:
        - openai/gpt-5
        - anthropic/claude-4-opus
        primary:
        - qwen/qwen-2.5-coder-32b-instruct
        - deepseek/deepseek-chat
      documenter:
        fallback:
        - mistralai/mistral-small-3
        - stability-ai/stablelm-2-12b
        never_use:
        - anthropic/claude-3-7-sonnet
        - openai/gpt-5
        primary:
        - meta-llama/llama-3.3-70b-instruct
        - google/gemma-3-12b
      researcher:
        fallback:
        - cohere/command-r
        - deepseek-ai/deepseek-v3
        never_use:
        - google/gemini-2.5-pro-exp
        - openai/gpt-5-pro
        primary:
        - meta-llama/llama-3.3-70b-instruct
        - 01-ai/yi-34b
      reviewer:
        fallback:
        - qwen/qwen-2.5-72b-instruct
        - mistralai/mistral-small-3
        never_use:
        - openai/o3-pro
        - anthropic/claude-sonnet-4.5
        primary:
        - deepseek/deepseek-chat
        - meta-llama/llama-3.3-70b-instruct
    name: Maximum Cost Efficiency
    quality_weight: 0.1
    speed_weight: 0.0
    thresholds:
      escalation_threshold: 0.6
      max_acceptable_latency: 60
      min_quality_score: 0.7
  PRIVACY_FIRST:
    cost_weight: 0.3
    description: Only use open-source models that can run locally. Zero data leakage.
    model_preferences:
      architect:
        fallback:
        - deepseek/deepseek-chat
        - 01-ai/yi-34b
        never_use:
        - openai/*
        - anthropic/*
        - google/*
        - perplexity/*
        primary:
        - meta-llama/llama-3.3-70b-instruct
        - qwen/qwen-2.5-72b-instruct
      coder:
        fallback:
        - mistralai/codestral-25.01
        - ibm/granite-code-34b-instruct
        never_use:
        - openai/*
        - anthropic/*
        - google/*
        primary:
        - qwen/qwen-2.5-coder-32b-instruct
        - deepseek/deepseek-chat
      documenter:
        fallback:
        - stability-ai/stablelm-2-12b
        - cohere/command-r
        never_use:
        - openai/*
        - anthropic/*
        - google/*
        primary:
        - meta-llama/llama-3.3-70b-instruct
        - mistralai/mistral-small-3
      researcher:
        fallback:
        - cohere/command-r-plus
        - deepseek/deepseek-chat
        never_use:
        - openai/*
        - anthropic/*
        - google/*
        - perplexity/*
        primary:
        - meta-llama/llama-3.3-70b-instruct
        - 01-ai/yi-34b
      reviewer:
        fallback:
        - qwen/qwen-2.5-72b-instruct
        - mistralai/mixtral-8x22b-instruct
        never_use:
        - openai/*
        - anthropic/*
        - google/*
        primary:
        - deepseek/deepseek-chat
        - meta-llama/llama-3.3-70b-instruct
    name: Maximum Privacy
    quality_weight: 0.5
    speed_weight: 0.2
    thresholds:
      escalation_threshold: 0.0
      max_acceptable_latency: 90
      min_quality_score: 0.75
  QUALITY_FIRST:
    cost_weight: 0.1
    description: Use the best models regardless of cost. Ideal for production-critical
      code.
    model_preferences:
      architect:
        fallback:
        - anthropic/claude-opus-4.1
        - openai/o3-pro
        never_use: []
        primary:
        - openai/gpt-5-pro
        - openai/o4-mini-high
        - google/gemini-2.5-pro-exp
      coder:
        fallback:
        - anthropic/claude-3-7-sonnet
        never_use: []
        primary:
        - anthropic/claude-sonnet-4.5
        - openai/gpt-5
        - anthropic/claude-4-opus
      documenter:
        fallback:
        - google/gemini-2.5-flash-exp
        never_use: []
        primary:
        - anthropic/claude-3-7-sonnet
        - openai/gpt-5
      researcher:
        fallback:
        - anthropic/claude-opus-4.1
        never_use: []
        primary:
        - google/gemini-2.5-pro-exp
        - openai/gpt-5-pro
        - perplexity/r1
      reviewer:
        fallback:
        - anthropic/claude-opus-4.1
        never_use: []
        primary:
        - anthropic/claude-sonnet-4.5
        - openai/gpt-5
        - openai/o3-pro
    name: Maximum Quality
    quality_weight: 0.9
    speed_weight: 0.0
    thresholds:
      escalation_threshold: 0.95
      max_acceptable_latency: 30
      min_quality_score: 0.9
  SPEED_FIRST:
    cost_weight: 0.2
    description: Fastest response times. Ideal for real-time applications.
    model_preferences:
      architect:
        fallback:
        - alibaba/qwen2.5-coder-7b-instruct
        - microsoft/phi-4
        never_use:
        - openai/gpt-5-pro
        - google/gemini-2.5-pro-exp
        primary:
        - google/gemini-2.5-flash-exp
        - mistralai/mistral-small-3
      coder:
        fallback:
        - microsoft/phi-4
        - google/gemma-3-4b
        never_use:
        - openai/gpt-5
        - deepseek-ai/deepseek-v3
        primary:
        - alibaba/qwen2.5-coder-7b-instruct
        - ibm/granite-code-8b-instruct
      documenter:
        fallback:
        - microsoft/phi-4
        - meta-llama/llama-3.1-8b-instruct
        never_use:
        - anthropic/claude-3-7-sonnet
        - meta-llama/llama-3.3-70b-instruct
        primary:
        - google/gemma-3-4b
        - stability-ai/stablelm-1.6b
      researcher:
        fallback:
        - cohere/command-r
        - 01-ai/yi-coder
        never_use:
        - google/gemini-2.5-pro-exp
        - perplexity/r1
        primary:
        - google/gemma-3-12b
        - mistralai/mistral-small-3
      reviewer:
        fallback:
        - ibm/granite-3.2-8b-instruct
        - stability-ai/stablelm-2-12b
        never_use:
        - anthropic/claude-sonnet-4.5
        - openai/o3-pro
        primary:
        - mistralai/mistral-small-3
        - google/gemma-3-12b
    name: Maximum Speed
    quality_weight: 0.3
    speed_weight: 0.5
    thresholds:
      escalation_threshold: 0.5
      max_acceptable_latency: 5
      min_quality_score: 0.6
ui_options:
  allow_strategy_override: true
  explain_selection: true
  show_cost_estimate: true
  show_model_selection: true
  show_quality_score: true
user_preference: COST_FIRST
